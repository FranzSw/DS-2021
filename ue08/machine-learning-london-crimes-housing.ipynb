{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-02-05T23:07:32.067059Z","iopub.execute_input":"2022-02-05T23:07:32.067461Z","iopub.status.idle":"2022-02-05T23:07:32.105011Z","shell.execute_reply.started":"2022-02-05T23:07:32.067365Z","shell.execute_reply":"2022-02-05T23:07:32.104159Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"## Loading london housing prices data","metadata":{}},{"cell_type":"code","source":"houses = pd.read_csv('/kaggle/input/housing-in-london/housing_in_london_monthly_variables.csv')","metadata":{"execution":{"iopub.status.busy":"2022-02-05T23:07:32.107011Z","iopub.execute_input":"2022-02-05T23:07:32.107512Z","iopub.status.idle":"2022-02-05T23:07:32.174614Z","shell.execute_reply.started":"2022-02-05T23:07:32.107468Z","shell.execute_reply":"2022-02-05T23:07:32.173965Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"## Loading london crime data\nThe london crime data is only accessible as big query dataset, so it is a bit more difficult to query it.\n\nTo merge it, we'll count the crime data per year per borough. We filter out boroughs outside of London to match the London housing dataset ","metadata":{}},{"cell_type":"code","source":"import bq_helper\nfrom bq_helper import BigQueryHelper\n\ncrime_bq = bq_helper.BigQueryHelper(active_project=\"bigquery-public-data\",\n                                   dataset_name=\"london_crime\")","metadata":{"execution":{"iopub.status.busy":"2022-02-05T23:07:32.175671Z","iopub.execute_input":"2022-02-05T23:07:32.175999Z","iopub.status.idle":"2022-02-05T23:07:32.186462Z","shell.execute_reply.started":"2022-02-05T23:07:32.175971Z","shell.execute_reply":"2022-02-05T23:07:32.185417Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# Get the number of crimes per year per borough\n# Split into following categories:\n# Theft and Handling, burglary, Robbery, Fraud or Forgery, Criminal Damage, Other Notifiable Offences\n# Drugs\n# Sexual Offences, Violence Against the Person\ncrimesPerYearPerBoroughQuery = \"\"\"\n  SELECT\n    year,\n    month,\n    borough,\n    SUM(IF(major_category IN UNNEST(SPLIT(\"Sexual Offences, Violence Against the Person\", \", \")), value, 0)) as no_personal_offenses,\n    SUM(IF(major_category IN UNNEST(SPLIT(\"Drugs\", \", \")), value, 0)) as no_drug_offenses,\n    SUM(IF(major_category IN UNNEST(SPLIT(\"Theft and Handling, burglary, Robbery, Fraud or Forgery, Criminal Damage, Other Notifiable Offences\", \", \")), value, 0)) as no_material_offenses,\n  FROM\n    `bigquery-public-data.london_crime.crime_by_lsoa`\n  GROUP BY\n    year,\n    month,\n    borough\n  ORDER BY\n    year\n;\n        \"\"\"\ncrimesPerYearPerBorough = crime_bq.query_to_pandas_safe(crimesPerYearPerBoroughQuery)\ncrimesPerYearPerBorough[100:200].head()","metadata":{"execution":{"iopub.status.busy":"2022-02-05T23:07:32.188094Z","iopub.execute_input":"2022-02-05T23:07:32.188813Z","iopub.status.idle":"2022-02-05T23:07:35.723977Z","shell.execute_reply.started":"2022-02-05T23:07:32.188756Z","shell.execute_reply":"2022-02-05T23:07:35.723158Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"## Lets have a look at the data\n\nFirst, lets see how many boroughs we have in both datasets to see how to merge it","metadata":{}},{"cell_type":"code","source":"crimesPerYearPerBorough['borough'].unique()","metadata":{"execution":{"iopub.status.busy":"2022-02-05T23:07:35.726595Z","iopub.execute_input":"2022-02-05T23:07:35.727364Z","iopub.status.idle":"2022-02-05T23:07:35.736203Z","shell.execute_reply.started":"2022-02-05T23:07:35.727314Z","shell.execute_reply":"2022-02-05T23:07:35.735400Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"houses['area'].unique()","metadata":{"execution":{"iopub.status.busy":"2022-02-05T23:07:35.738110Z","iopub.execute_input":"2022-02-05T23:07:35.738908Z","iopub.status.idle":"2022-02-05T23:07:35.749480Z","shell.execute_reply.started":"2022-02-05T23:07:35.738866Z","shell.execute_reply":"2022-02-05T23:07:35.748555Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"As we can see, the houses dataset also contains surrounding areas of london and writes everything lowercase. Let's see if merging works as expected with applying some transformations:","metadata":{}},{"cell_type":"code","source":"# Only keep the year, as the date is always set to 1-12-YEAR anyway\nhouses['year'] = houses['date'].str.split('-', 1, expand=True)[0].astype(int)\nhouses['month'] = houses['date'].str.split('-', 2, expand=True)[1].astype(int)\nhouses.info()","metadata":{"execution":{"iopub.status.busy":"2022-02-05T23:07:35.752130Z","iopub.execute_input":"2022-02-05T23:07:35.752816Z","iopub.status.idle":"2022-02-05T23:07:35.830250Z","shell.execute_reply.started":"2022-02-05T23:07:35.752784Z","shell.execute_reply":"2022-02-05T23:07:35.829371Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"crimesPerYearPerBorough['borough'] = crimesPerYearPerBorough['borough'].str.lower()","metadata":{"execution":{"iopub.status.busy":"2022-02-05T23:07:35.832034Z","iopub.execute_input":"2022-02-05T23:07:35.832605Z","iopub.status.idle":"2022-02-05T23:07:35.839524Z","shell.execute_reply.started":"2022-02-05T23:07:35.832563Z","shell.execute_reply":"2022-02-05T23:07:35.838613Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"expectedMergeCount = len(crimesPerYearPerBorough['borough'].unique())\n\ncrimesTestFrame = pd.DataFrame(crimesPerYearPerBorough['borough'].unique())\ncrimesTestFrame[0] = crimesTestFrame[0].str.lower()\nprint(f\"Expected: {expectedMergeCount}\")\nprint(f\"Actual: {len(crimesTestFrame.merge(pd.DataFrame(houses['area'].unique())))}\")","metadata":{"execution":{"iopub.status.busy":"2022-02-05T23:07:35.840922Z","iopub.execute_input":"2022-02-05T23:07:35.841445Z","iopub.status.idle":"2022-02-05T23:07:35.864969Z","shell.execute_reply.started":"2022-02-05T23:07:35.841397Z","shell.execute_reply":"2022-02-05T23:07:35.864154Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"Additionally, ","metadata":{}},{"cell_type":"markdown","source":"Nice, it works! Lets merge the frames and look at the columns","metadata":{}},{"cell_type":"code","source":"df = crimesPerYearPerBorough.merge(houses, left_on=['year', 'month', 'borough'], right_on=['year', 'month', 'area'])\ndf.dropna(axis=0, how=\"all\", inplace=True)\nprint(df.info())\ndf[100:200].head()","metadata":{"execution":{"iopub.status.busy":"2022-02-05T23:07:35.866350Z","iopub.execute_input":"2022-02-05T23:07:35.866554Z","iopub.status.idle":"2022-02-05T23:07:35.912213Z","shell.execute_reply.started":"2022-02-05T23:07:35.866530Z","shell.execute_reply":"2022-02-05T23:07:35.911448Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"### Split into test and training dataset","metadata":{}},{"cell_type":"code","source":"# Define the columns we expect as input and output\nX_cols = ['no_personal_offenses', 'no_drug_offenses', 'no_material_offenses']\ny_cols = ['average_price']","metadata":{"execution":{"iopub.status.busy":"2022-02-05T23:07:35.913485Z","iopub.execute_input":"2022-02-05T23:07:35.913763Z","iopub.status.idle":"2022-02-05T23:07:35.920065Z","shell.execute_reply.started":"2022-02-05T23:07:35.913730Z","shell.execute_reply":"2022-02-05T23:07:35.919041Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"\nml_df = df[X_cols + y_cols]\nml_df = ml_df.dropna()\n# ml_df = ml_df[(ml_df != 0).all(1)]\n\nX, y = ml_df[X_cols], ml_df[y_cols]\n\n# Optional if just one column (transforms 1D array in array of 1-element arrays)\ny = y.values.ravel()","metadata":{"execution":{"iopub.status.busy":"2022-02-05T23:07:35.921786Z","iopub.execute_input":"2022-02-05T23:07:35.922099Z","iopub.status.idle":"2022-02-05T23:07:35.939887Z","shell.execute_reply.started":"2022-02-05T23:07:35.922057Z","shell.execute_reply":"2022-02-05T23:07:35.938811Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"Now, we want to split it into test and training set randomly","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# train_test_split shuffles the data and then splits it according to test_size. As we have not so much data, we \n# Reduce the test size a bit to 20%, but might have a look at how this affects training later\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=1)","metadata":{"execution":{"iopub.status.busy":"2022-02-05T23:07:35.941368Z","iopub.execute_input":"2022-02-05T23:07:35.942201Z","iopub.status.idle":"2022-02-05T23:07:36.887502Z","shell.execute_reply.started":"2022-02-05T23:07:35.942133Z","shell.execute_reply":"2022-02-05T23:07:36.886622Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"from matplotlib import pyplot as plt\n\nprint(X_train.describe())\nprint(X_val.describe())\nX_test.describe()\n\nfig, axs = plt.subplots(1, 3, figsize=(12, 3.5), dpi=160)\n\nplt = axs[0]\ncol = X_cols[0]\nplt.boxplot([X_train[col], X_test[col], X_val[col]])\nplt.set_title('Personal Offenses')\nplt.set_xticks([1, 2, 3], ['Train', 'Test', 'Validation'])\n\nplt = axs[1]\ncol = X_cols[1]\nplt.boxplot([X_train[col], X_test[col], X_val[col]])\nplt.set_title('Drug Offenses')\nplt.set_xticks([1, 2, 3], ['Train', 'Test', 'Validation'])\n\nplt = axs[2]\ncol = X_cols[2]\nplt.boxplot([X_train[col], X_test[col], X_val[col]])\nplt.set_title('Material Offenses')\nplt.set_xticks([1, 2, 3], ['Train', 'Test', 'Validation'])","metadata":{"execution":{"iopub.status.busy":"2022-02-05T23:07:36.891355Z","iopub.execute_input":"2022-02-05T23:07:36.891677Z","iopub.status.idle":"2022-02-05T23:07:37.618971Z","shell.execute_reply.started":"2022-02-05T23:07:36.891639Z","shell.execute_reply":"2022-02-05T23:07:37.618304Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"# 2 â€” Training ML Models","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\nrfr = RandomForestRegressor()\nrfr.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2022-02-05T23:07:37.619947Z","iopub.execute_input":"2022-02-05T23:07:37.620157Z","iopub.status.idle":"2022-02-05T23:07:38.657353Z","shell.execute_reply.started":"2022-02-05T23:07:37.620131Z","shell.execute_reply":"2022-02-05T23:07:38.656332Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"rfr.score(X_val, y_val)","metadata":{"execution":{"iopub.status.busy":"2022-02-05T23:07:38.658943Z","iopub.execute_input":"2022-02-05T23:07:38.659256Z","iopub.status.idle":"2022-02-05T23:07:38.703875Z","shell.execute_reply.started":"2022-02-05T23:07:38.659215Z","shell.execute_reply":"2022-02-05T23:07:38.702751Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"Thats already better than a constant output would be, but lets see if we can optimize it","metadata":{}},{"cell_type":"code","source":"for i in range(10,200,10):\n    rfr = RandomForestRegressor(n_estimators=i)\n    rfr.fit(X_train, y_train)\n    print(f\"{i} trees: {rfr.score(X_val, y_val)}\")","metadata":{"execution":{"iopub.status.busy":"2022-02-05T23:07:38.705747Z","iopub.execute_input":"2022-02-05T23:07:38.706116Z","iopub.status.idle":"2022-02-05T23:07:50.941481Z","shell.execute_reply.started":"2022-02-05T23:07:38.706068Z","shell.execute_reply":"2022-02-05T23:07:50.940147Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"Looks like 80 trees seems to be a sweet spot, but all pretty similar","metadata":{}},{"cell_type":"code","source":"for min_leaf in range(1,10,2):\n    for min_split in range(2,20,2):\n        for i in range(50,130,20):\n            rfr = RandomForestRegressor(n_estimators=100, min_samples_split=min_split, min_samples_leaf=min_leaf)\n            rfr.fit(X_train, y_train)\n            print(f\"{min_leaf} -- {min_split} -- {i} trees: {rfr.score(X_val, y_val)}\")","metadata":{"execution":{"iopub.status.busy":"2022-02-05T23:07:50.942480Z","iopub.status.idle":"2022-02-05T23:07:50.943028Z","shell.execute_reply.started":"2022-02-05T23:07:50.942746Z","shell.execute_reply":"2022-02-05T23:07:50.942772Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"It also looks like a higher min_samples_split improves performance a bit","metadata":{}},{"cell_type":"code","source":"rfr = RandomForestRegressor(n_estimators=100, min_samples_split=15, min_samples_leaf=10)\nrfr.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2022-02-05T23:07:54.916616Z","iopub.execute_input":"2022-02-05T23:07:54.917258Z","iopub.status.idle":"2022-02-05T23:07:55.446873Z","shell.execute_reply.started":"2022-02-05T23:07:54.917217Z","shell.execute_reply":"2022-02-05T23:07:55.446233Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error\n\ndef evaluate(model, X_t = X_test, y_t = y_test):\n    predictions = model.predict(X_t)\n    house_price_e = mean_absolute_error(y_t, predictions)\n\n    house_sqr_price_e = mean_squared_error(y_t, predictions)\n    \n    print('Score')\n    print(model.score(X_t, y_t))\n    print('Mean Abs Error')\n    print(house_price_e)\n    return model.score(X_t, y_t), house_price_e\n    # print('Root Mean Squared Error')\n    # print(np.sqrt(house_sqr_price_e), np.sqrt(house_sqr_count_e))","metadata":{"execution":{"iopub.status.busy":"2022-02-05T23:07:56.960704Z","iopub.execute_input":"2022-02-05T23:07:56.960968Z","iopub.status.idle":"2022-02-05T23:07:56.968124Z","shell.execute_reply.started":"2022-02-05T23:07:56.960923Z","shell.execute_reply":"2022-02-05T23:07:56.966959Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"evaluate(rfr)\nplt.boxplot(y_test)","metadata":{"execution":{"iopub.status.busy":"2022-02-05T23:07:59.600015Z","iopub.execute_input":"2022-02-05T23:07:59.600308Z","iopub.status.idle":"2022-02-05T23:07:59.824067Z","shell.execute_reply.started":"2022-02-05T23:07:59.600262Z","shell.execute_reply":"2022-02-05T23:07:59.823239Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"Well that is a high error...","metadata":{}},{"cell_type":"code","source":"# Linear Regression model\nfrom sklearn.linear_model import LinearRegression\n\nlrm = LinearRegression()\nlrm.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2022-02-05T23:08:02.539815Z","iopub.execute_input":"2022-02-05T23:08:02.540092Z","iopub.status.idle":"2022-02-05T23:08:02.562959Z","shell.execute_reply.started":"2022-02-05T23:08:02.540059Z","shell.execute_reply":"2022-02-05T23:08:02.562338Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"lrm.score(X_test, y_test)","metadata":{"execution":{"iopub.status.busy":"2022-02-05T23:08:04.439107Z","iopub.execute_input":"2022-02-05T23:08:04.439946Z","iopub.status.idle":"2022-02-05T23:08:04.448698Z","shell.execute_reply.started":"2022-02-05T23:08:04.439890Z","shell.execute_reply":"2022-02-05T23:08:04.447771Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"evaluate(lrm)","metadata":{"execution":{"iopub.status.busy":"2022-02-05T23:08:07.879647Z","iopub.execute_input":"2022-02-05T23:08:07.879935Z","iopub.status.idle":"2022-02-05T23:08:07.895400Z","shell.execute_reply.started":"2022-02-05T23:08:07.879907Z","shell.execute_reply":"2022-02-05T23:08:07.894674Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"from matplotlib import pyplot as plt\nimport pandas as pd\n\nmodel = rfr\ny_pred = model.predict(X_test)\ny_error = y_pred - y_test\n\nX_all = X_test.copy(deep=True)\nX_all['error'] = y_error\n\nfig, axs = plt.subplots(1, 3, figsize=(12, 3.5), dpi=160)\n\nplt = axs[0]\ncol = X_cols[0]\nplt.scatter(X_all[col], X_all['error'])\nplt.set_title('Personal Offenses')\nplt.set_ylabel('Error')\nplt.set_xlabel('Offenses')\n\nplt = axs[1]\ncol = X_cols[1]\nplt.scatter(X_all[col], X_all['error'])\nplt.set_title('Drug Offenses')\nplt.set_ylabel('Error')\nplt.set_xlabel('Offenses')\n\nplt = axs[2]\ncol = X_cols[2]\nplt.scatter(X_all[col], X_all['error'])\nplt.set_title('Material Offenses')\nplt.set_ylabel('Error')\nplt.set_xlabel('Offenses')\n\nX_all\n# X_all['BUCKET'] = pd.qcut(X_all['error'], 20)\n# X_all.plot(column='no_personal_offenses', by='BUCKET')","metadata":{"execution":{"iopub.status.busy":"2022-02-05T23:08:07.896796Z","iopub.execute_input":"2022-02-05T23:08:07.897760Z","iopub.status.idle":"2022-02-05T23:08:08.538268Z","shell.execute_reply.started":"2022-02-05T23:08:07.897724Z","shell.execute_reply":"2022-02-05T23:08:08.537709Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n# Calculate error per area\nml_df = df[X_cols + y_cols + ['area']]\nml_df = ml_df.dropna()\nX, y = ml_df[X_cols + ['area']], ml_df[y_cols]\n# As the random_state is the same -> test set is the same\n_, X_test2, _, y_test2 = train_test_split(X, y, test_size=0.2, random_state=1)\n\nareas = {}\nfor area in X_test2['area'].unique():\n    indices = np.where(X_test2['area'] == area)\n    _, areas[area] = evaluate(lrm, X_test2[X_cols].values[indices], y_test2.values[indices])\n    \n# import matplotlib.pylab as plt\n\nplt.tick_params(bottom=False)\nlists = sorted(areas.items(),key=lambda item: item[1]) # sorted by key, return a list of tuples\nx, y = zip(*lists) # unpack a list of pairs into two tuples\nprint(x, y)\nplt.plot(x, y, 'bo')\n# plt.set_xlabel('Mean absolute error')\n# plt.set_ylabel('Area')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-05T23:08:08.539310Z","iopub.execute_input":"2022-02-05T23:08:08.539684Z","iopub.status.idle":"2022-02-05T23:08:09.031553Z","shell.execute_reply.started":"2022-02-05T23:08:08.539654Z","shell.execute_reply":"2022-02-05T23:08:09.029608Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n# Calculate error per area\nml_df = df[X_cols + y_cols + ['area']]\nml_df = ml_df.dropna()\nX, y = ml_df[X_cols + ['area']], ml_df[y_cols]\n# As the random_state is the same -> test set is the same\n_, X_test2, _, y_test2 = train_test_split(X, y, test_size=0.2, random_state=1)\n\nareas = {}\nfor area in X_test2['area'].unique():\n    indices = np.where(X_test2['area'] == area)\n    _, areas[area] = evaluate(rfr, X_test2[X_cols].values[indices], y_test2.values[indices])\n    \n# import matplotlib.pylab as plt\n\nplt.tick_params(bottom=False)\nlists = { k: areas[k] for k in x } # sorted by key, return a list of tuples\nx2, y2 = zip(*(lists.items())) # unpack a list of pairs into two tuples\nprint(x2, y2)\nplt.plot(x2, y2, 'bo')\n# plt.set_xlabel('Mean absolute error')\n# plt.set_ylabel('Area')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-05T23:08:09.033490Z","iopub.execute_input":"2022-02-05T23:08:09.033718Z","iopub.status.idle":"2022-02-05T23:08:10.363839Z","shell.execute_reply.started":"2022-02-05T23:08:09.033690Z","shell.execute_reply":"2022-02-05T23:08:10.363197Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"X['area'].values.reshape((-1,1)).shape","metadata":{"execution":{"iopub.status.busy":"2022-02-05T23:08:10.364772Z","iopub.execute_input":"2022-02-05T23:08:10.365199Z","iopub.status.idle":"2022-02-05T23:08:10.371668Z","shell.execute_reply.started":"2022-02-05T23:08:10.365164Z","shell.execute_reply":"2022-02-05T23:08:10.370827Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":"## Training only on area","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder\n\nml_df = df[y_cols + ['area']]\nml_df = ml_df.dropna()\nX, y = ml_df[['area']], ml_df[y_cols]\n\nohe = OneHotEncoder()\nohe.fit(X['area'].unique().reshape((-1,1)))\nX = ohe.transform(X['area'].values.reshape((-1,1)))\n# As the random_state is the same -> test set is the same\nX_train2, X_test2, y_train2, y_test2 = train_test_split(X, y, test_size=0.2, random_state=1)\nX_train2, _, y_train2, _ = train_test_split(X_train2, y_train2, test_size=0.25, random_state=1)\n\nrfr2 = RandomForestRegressor()\nrfr2.fit(X_train2, y_train2)\nevaluate(rfr2, X_test2, y_test2)","metadata":{"execution":{"iopub.status.busy":"2022-02-05T23:08:10.373028Z","iopub.execute_input":"2022-02-05T23:08:10.373262Z","iopub.status.idle":"2022-02-05T23:08:10.699763Z","shell.execute_reply.started":"2022-02-05T23:08:10.373232Z","shell.execute_reply":"2022-02-05T23:08:10.698946Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"markdown","source":"## Leave area out","metadata":{}},{"cell_type":"code","source":"# Change model / boroughs for different results:\nfrom sklearn.preprocessing import OneHotEncoder\n\nml_df = df[X_cols + y_cols + ['area']]\nml_df = ml_df.dropna()\n# ml_df = ml_df[(ml_df != 0).all(1)]\n\nX, y = ml_df[X_cols + ['area']], ml_df[y_cols]\n\n# Optional if just one column (transforms 1D array in array of 1-element arrays)\ny = y.values.ravel()\n\n# Two areas randomly selected from the ones which had no outlying error\nsplit_indices = np.where((X['area'] == 'tower hamlets') | (X['area'] == 'islington'))\nsplit_indices_anti = np.where(~((X['area'] == 'tower hamlets') | (X['area'] == 'islington')))\n\nX = X[X_cols]\n\n# As the random_state is the same -> test set is the same\nX_train2, X_test2, y_train2, y_test2 = X.values[split_indices_anti], X.values[indices], y[split_indices_anti], y[indices]\nX_train2, _, y_train2, _ = train_test_split(X_train2, y_train2, test_size=0.25, random_state=1)\n\nrfr2 = RandomForestRegressor()\nrfr2.fit(X_train2, y_train2)\nprint(evaluate(rfr2, X_test2, y_test2))\n\nlrm2 = LinearRegression()\nlrm2.fit(X_train2, y_train2)\nevaluate(lrm2, X_test2, y_test2)","metadata":{"execution":{"iopub.status.busy":"2022-02-05T23:09:14.285104Z","iopub.execute_input":"2022-02-05T23:09:14.285630Z","iopub.status.idle":"2022-02-05T23:09:15.211854Z","shell.execute_reply.started":"2022-02-05T23:09:14.285585Z","shell.execute_reply":"2022-02-05T23:09:15.211245Z"},"trusted":true},"execution_count":30,"outputs":[]}]}